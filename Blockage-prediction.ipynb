{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6762286,"sourceType":"datasetVersion","datasetId":3891975},{"sourceId":7013149,"sourceType":"datasetVersion","datasetId":4032294},{"sourceId":7175894,"sourceType":"datasetVersion","datasetId":4146734}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["!pip install torchsummary"],"metadata":{"execution":{"iopub.status.busy":"2023-12-11T13:20:57.475246Z","iopub.execute_input":"2023-12-11T13:20:57.476101Z","iopub.status.idle":"2023-12-11T13:21:08.953375Z","shell.execute_reply.started":"2023-12-11T13:20:57.476067Z","shell.execute_reply":"2023-12-11T13:21:08.952181Z"},"trusted":true,"id":"CsoMlcOIXP4P","outputId":"5c5bcacd-6939-4a05-a423-487e1d8ae663"},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n","output_type":"stream"}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","from sklearn.metrics import accuracy_score, f1_score\n","import pandas as pd\n","\n","\n","\n","# Assuming your CSV files are named train.csv, test.csv, and validate.csv\n","train_csv_path = '/kaggle/input/future-5-and-10-excel-data-scenario17/scenario17_dev_series_train_5.csv'\n","test_csv_path = '/kaggle/input/future-5-and-10-excel-data-scenario17/scenario17_dev_series_test_5.csv'\n","validate_csv_path = '/kaggle/input/future-5-and-10-excel-data-scenario17/scenario17_dev_series_val_5.csv'\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, csv_path):\n","        self.data = pd.read_csv(csv_path)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # Load and preprocess the images\n","        image_paths = ['/kaggle/input/scenario-17-dataset/scenario17_vision/dev_data/' + str(path).lstrip('.') for path in self.data.iloc[idx, 1:9].values]\n","        images = [Image.open(path).convert('RGB') for path in image_paths]\n","\n","        transform = transforms.Compose([\n","            transforms.Resize((64, 64)),  # Resize images to match the expected input size\n","            transforms.ToTensor(),\n","        ])\n","        images = [transform(img) for img in images]\n","        images = torch.stack(images)\n","\n","        # Load the target\n","        target_value = self.data.iloc[idx,15]\n","\n","        target = torch.tensor(int(target_value))\n","\n","#         print(\"images - \",images)\n","        return images, target\n","\n","train_dataset = CustomDataset(train_csv_path)\n","test_dataset = CustomDataset(test_csv_path)\n","validate_dataset = CustomDataset(validate_csv_path)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","validate_loader = DataLoader(validate_dataset, batch_size=64, shuffle=False)\n"],"metadata":{"execution":{"iopub.status.busy":"2023-12-11T13:21:19.105752Z","iopub.execute_input":"2023-12-11T13:21:19.106478Z","iopub.status.idle":"2023-12-11T13:21:19.149713Z","shell.execute_reply.started":"2023-12-11T13:21:19.106441Z","shell.execute_reply":"2023-12-11T13:21:19.148957Z"},"trusted":true,"id":"aoX08MSPXP4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"trusted":true,"id":"IsagRhloXP4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class CNNBlock(nn.Module):\n","    def __init__(self):\n","        super(CNNBlock, self).__init__()\n","        self.cnn_layers = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(64),\n","                nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","                nn.BatchNorm2d(128),\n","                nn.ReLU(),\n","                nn.MaxPool2d(8),\n","                nn.MaxPool2d(8),\n","            ) for _ in range(8)  # 8 parallel CNN layers\n","        ])\n","\n","        self.dense_layers = nn.ModuleList([\n","            nn.Linear(1 * 1 * 128, 4) for _ in range(8)  # Dense layer for each CNN layer\n","        ])\n","\n","    def forward(self, x):\n","        cnn_outputs = []\n","        for i in range(8):\n","            cnn_output = self.cnn_layers[i](x[:, i, :, :, :])\n","#             print(cnn_output)\n","#             print(cnn_output.size())\n","            cnn_output = cnn_output.view(cnn_output.size(0), -1)  # Flatten the output\n","#             print(cnn_output.size())\n","            dense_output = self.dense_layers[i](cnn_output)\n","#             print(dense_output)\n","#             print(dense_output.size())\n","            cnn_outputs.append(dense_output)\n","\n","\n","        return cnn_outputs\n","\n","\n","class LSTMModel(nn.Module):\n","    def __init__(self):\n","        super(LSTMModel, self).__init__()\n","        self.cnn_block = CNNBlock()\n","        self.lstm = nn.LSTM(input_size=4, hidden_size=64, batch_first=True)\n","        self.fc = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        cnn_outputs = self.cnn_block(x)\n","        #print(len(cnn_outputs))\n","\n","        cnn_outputs = torch.stack(cnn_outputs, dim=1)  # Stack along the sequence dimension\n","\n","        lstm_out, _ = self.lstm(cnn_outputs)\n","\n","        lstm_out = lstm_out[:, -1, :]  # Take the last time step output\n","        #print(lstm_out)\n","        output = self.fc(lstm_out)\n","\n","        return output\n","\n","# Instantiate the model\n","model = LSTMModel()\n"],"metadata":{"execution":{"iopub.status.busy":"2023-12-11T13:21:29.826286Z","iopub.execute_input":"2023-12-11T13:21:29.827213Z","iopub.status.idle":"2023-12-11T13:21:29.858375Z","shell.execute_reply.started":"2023-12-11T13:21:29.827178Z","shell.execute_reply":"2023-12-11T13:21:29.857505Z"},"trusted":true,"id":"CcJ5ZRsvXP4U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(model)"],"metadata":{"execution":{"iopub.status.busy":"2023-12-11T13:21:31.264772Z","iopub.execute_input":"2023-12-11T13:21:31.265652Z","iopub.status.idle":"2023-12-11T13:21:31.271083Z","shell.execute_reply.started":"2023-12-11T13:21:31.265618Z","shell.execute_reply":"2023-12-11T13:21:31.270158Z"},"trusted":true,"id":"5zeKfyn3XP4V","outputId":"57537988-b3f7-484b-b618-3a74d90264fe"},"execution_count":null,"outputs":[{"name":"stdout","text":"LSTMModel(\n  (cnn_block): CNNBlock(\n    (cnn_layers): ModuleList(\n      (0-7): 8 x Sequential(\n        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): MaxPool2d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n        (6): MaxPool2d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n      )\n    )\n    (dense_layers): ModuleList(\n      (0-7): 8 x Linear(in_features=128, out_features=4, bias=True)\n    )\n  )\n  (lstm): LSTM(4, 64, batch_first=True)\n  (fc): Linear(in_features=64, out_features=1, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":["image_shape = (3, 64, 64)\n","num_classes = 2\n","\n","sequence_length = 8\n","num_epochs = 25\n","learning_rate = 0.001\n","hidden_size = 64\n","num_layers = 1"],"metadata":{"execution":{"iopub.status.busy":"2023-12-11T13:21:33.340292Z","iopub.execute_input":"2023-12-11T13:21:33.340653Z","iopub.status.idle":"2023-12-11T13:21:33.345371Z","shell.execute_reply.started":"2023-12-11T13:21:33.340625Z","shell.execute_reply":"2023-12-11T13:21:33.344473Z"},"trusted":true,"id":"OrWe0Vb6XP4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","# Assuming binary classification, change num_classes accordingly if needed\n","num_classes = 2\n","\n","# Instantiate the model\n","model = LSTMModel()\n","\n","# Check for GPU availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Loss function and optimizer\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","max_gradient_norm = 1.0\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()  # Set the model to training mode\n","    total_loss = 0\n","    correct = 0\n","    total_samples = 0\n","    all_predictions = []\n","    all_labels = []\n","\n","    for inputs, labels in train_loader:\n","        # Move data to GPU if available\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Assuming labels are 0 or 1, make sure they are float tensors\n","        labels = labels.float().view(-1, 1)\n","\n","        # Calculate loss\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_gradient_norm)\n","        optimizer.step()\n","\n","        # Update statistics\n","        total_loss += loss.item()\n","        predictions = (torch.sigmoid(outputs) > 0.5).float()  # Convert logits to probabilities and threshold at 0.5\n","        correct += (predictions == labels).sum().item()\n","        total_samples += labels.size(0)\n","\n","        # Collect predictions and labels for later evaluation\n","        all_predictions.extend(predictions.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","\n","        # Debugging information during training\n","#         print(\"Training Predictions:\", predictions)\n","#         print(\"Training Labels:\", labels)\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(all_labels, all_predictions)\n","    f1 = f1_score(all_labels, all_predictions)\n","\n","    # Print training statistics\n","    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss / len(train_loader)}, Accuracy: {accuracy}, F1 Score: {f1}')\n","\n","\n","torch.save(model.state_dict(), 'lstm_model_weights.pth')"],"metadata":{"execution":{"iopub.status.busy":"2023-12-11T13:21:35.310214Z","iopub.execute_input":"2023-12-11T13:21:35.310540Z"},"trusted":true,"id":"hw7tIldIXP4V","outputId":"6e02b793-16ce-48d4-846f-26a8cf37f7b8"},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [1/25], Loss: 0.6063473701477051, Accuracy: 0.7037037037037037, F1 Score: 0.7059569074778199\n","output_type":"stream"}]},{"cell_type":"code","source":["for test_inputs, test_labels in test_loader:\n","    print(\"inputs \",test_inputs)\n","    print(\"labels \",test_labels)"],"metadata":{"execution":{"iopub.status.busy":"2023-12-11T06:59:46.156255Z","iopub.execute_input":"2023-12-11T06:59:46.157223Z","iopub.status.idle":"2023-12-11T06:59:52.180170Z","shell.execute_reply.started":"2023-12-11T06:59:46.157175Z","shell.execute_reply":"2023-12-11T06:59:52.179194Z"},"trusted":true,"id":"dBUMm7U4XP4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","model.eval()  # Set the model to evaluation mode\n","test_correct = 0\n","test_total_samples = 0\n","test_all_predictions = []\n","test_all_labels = []\n","\n","with torch.no_grad():\n","    for test_inputs, test_labels in test_loader:\n","        # Move data to GPU if available\n","        test_inputs, test_labels = test_inputs.to(device), test_labels.to(device)\n","\n","        # Forward pass\n","        test_outputs = model(test_inputs)\n","\n","        # Assuming labels are 0 or 1, make sure they are float tensors\n","#         test_labels = test_labels.float().view(-1, 1)\n","\n","        # Apply sigmoid activation to get probabilities\n","        test_probs = torch.sigmoid(test_outputs)\n","\n","        # Apply threshold at 0.5 to get binary predictions\n","        test_predictions = (test_probs > 0.5).float()\n","\n","        test_correct += (test_predictions == test_labels).sum().item()\n","        test_total_samples += test_labels.size(0)\n","\n","        # Collect test predictions and labels for later evaluation\n","        test_all_predictions.extend(test_predictions.cpu().numpy())\n","        test_all_labels.extend(test_labels.cpu().numpy())\n","\n","\n","# Convert true labels to binary format\n","test_all_labels_binary = np.array(test_all_labels).astype(int)\n","test_all_predictions_binary = np.array(test_all_predictions).astype(int)\n","\n","# Debugging information\n","print(\"Binary Test Labels:\", test_all_labels_binary)\n","print(\"Binary Test Predictions:\", test_all_predictions_binary)\n","\n","# Calculate test metrics with the correct binary format\n","test_accuracy = accuracy_score(test_all_labels_binary, test_all_predictions_binary)\n","test_f1 = f1_score(test_all_labels_binary, test_all_predictions_binary, average='macro')\n","\n","# Print test statistics\n","print(f'Test Accuracy: {test_accuracy}, Test F1 Score: {test_f1}')"],"metadata":{"execution":{"iopub.status.busy":"2023-12-11T09:25:43.866036Z","iopub.execute_input":"2023-12-11T09:25:43.867216Z","iopub.status.idle":"2023-12-11T09:25:48.743135Z","shell.execute_reply.started":"2023-12-11T09:25:43.867164Z","shell.execute_reply":"2023-12-11T09:25:48.742102Z"},"trusted":true,"id":"vmha8s5CXP4X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OEtkl4RrXP4X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"971THNrIXP4X"},"execution_count":null,"outputs":[]}]}
